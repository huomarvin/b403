{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# 主内置 LCEL 可运行程序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46ff75-72ab-4391-904f-459bae77fc7a",
   "metadata": {},
   "source": [
    "## 内容\n",
    "* 可运行的透传。\n",
    "* 可运行的 Lambda。\n",
    "* 可运行的并行。\n",
    "    * 项获取器。\n",
    "* 可运行的分支。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fbb27-418c-4938-a82f-a40a01cba0ee",
   "metadata": {},
   "source": [
    "## 创建您的 .env 文件\n",
    "* 在 GitHub 仓库中，我们包括一个名为 .env.example 的文件\n",
    "* 将该文件重命名为 .env 文件，此处您将添加您的机密 API 密钥。请记得包括：\n",
    "* OPENAI_API_KEY=您的_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=您的_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=您的项目名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "我们将把我们的LangSmith项目称为**005-builtin-runnables**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe937d-dce4-43e7-a647-7a86dbd37923",
   "metadata": {},
   "source": [
    "## 可运行的传递\n",
    "* 它对输入数据不做任何处理。\n",
    "* 让我们在一个非常简单的例子中看看：一个仅包含 RunnablePassthrough() 的链将输出原始输入而不进行任何修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb318d05-70ee-4f57-81a3-9a512f10bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a4b9de-a4b3-4687-82b7-dcfe910f23de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abram'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94758c3-95fc-465b-aec1-8048ab161d45",
   "metadata": {},
   "source": [
    "## RunnableLambda\n",
    "* 要在 LCEL 链中使用自定义函数，我们需要用 RunnableLambda 将其包装起来。\n",
    "* 让我们定义一个非常简单的函数来创建俄语姓氏："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3438c0-05c3-48ab-a1eb-60209717cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c8c84-94b5-4fcc-910b-915db65bc9a7",
   "metadata": {},
   "source": [
    "* 为了在 LCEL 链中使用此功能，我们将使用 RunnableLambda():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26bbdd15-32b8-4594-9395-a33c74e95fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9bdaa7-0cc8-49f8-9aeb-b0ddece0d55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abramovich'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b8f10-0138-432f-b694-8a5360422221",
   "metadata": {},
   "source": [
    "* 如您所见，我们的链现在正在将 russian_lastname 函数应用于我们的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95190509-301b-4be2-9b8b-7dc17193bfee",
   "metadata": {},
   "source": [
    "## RunnableParallel\n",
    "* 我们将使用 RunnableParallel() 来并行运行任务。\n",
    "* 这可能是 LangChain 中最重要和最有用的 Runnable。\n",
    "* 在以下链中，RunnableParallel 将并行运行这两个任务：\n",
    "    * operation_a 将使用 RunnablePassthrough。\n",
    "    * operation_b 将使用带有 russian_lastname 函数的 RunnableLambda。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6bef0b-399d-43b8-9455-b7f2a9050172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ac0a07-6bec-4cc3-9049-b1ea49d560b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Abram', 'operation_b': 'Abramovich'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5372a0-a33e-4a02-9f84-43292bcde994",
   "metadata": {},
   "source": [
    "* 我们将不再使用 RunnableLambda，而是使用一个 lambda 函数，并将以两个输入调用链："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971fa8a7-5866-4716-9c4f-67260283c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": lambda x: x[\"name\"]+\"ovich\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b45b1a-6352-4618-a5e3-6cbda7236404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': {'name1': 'Jordam', 'name': 'Abram'},\n",
       " 'soccer_player': 'Abramovich'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3cd68-c918-4b4d-9769-bbaee8adb208",
   "metadata": {},
   "source": [
    "* 查看 lambda 函数如何接收 \"name\" 输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7891ee-c48c-4a26-8b24-1465a43f774e",
   "metadata": {},
   "source": [
    "#### 我们可以向链中添加更多的可运行任务\n",
    "* 在以下示例中，提示可运行任务将获取可运行并行任务的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f786101f-a555-445f-8c26-29d9b65a37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dece6a57-ef92-4ca8-af7c-cfbd0b9a03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea6be27-c67f-4bf0-a3db-99d716778486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a234758-44f5-4bdc-a1ea-ff972e23ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": RunnableLambda(russian_lastname_from_dictionary),\n",
    "        \"operation_c\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83889244-92be-4d35-a439-82c0949ccdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Roman Abramovich is that he has a personal net worth estimated to be around $14 billion, making him one of the richest individuals in Russia. He made his fortune primarily through investments in oil and gas companies, as well as through his ownership of the Chelsea Football Club in the English Premier League. Despite his immense wealth, Abramovich is known for his philanthropic efforts, having donated millions of dollars to various charities and causes over the years.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1f143-f7eb-4f86-9f49-e4dc8c249451",
   "metadata": {},
   "source": [
    "* As you saw, the prompt Runnable took \"Abramovich\", the output of the RunnableParallel, as the value for the \"soccer_player\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f9c36-ff04-4ac2-9794-503b021018dd",
   "metadata": {},
   "source": [
    "## 让我们看看 RunnableParallel 的更高级用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "999c0201-35df-4ebf-b46e-be0ef40f672c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Alumni of AI Accelera are individuals from all continents and top companies.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"AI Accelera has trained more than 10,000 Alumni from all continents and top companies\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"who are the Alumni of AI Accelera?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9fdb9-f85f-4b14-9cd4-7cf3f841295b",
   "metadata": {},
   "source": [
    "#### 重要提示：RunnableParallel 的语法可以有多种变体。\n",
    "* 在将 RunnableParallel 与另一个 Runnable 组合时，不需要将其封装在 RunnableParallel 类中。 在链中，以下三种语法是等价的：\n",
    "    * `RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})`\n",
    "    * `RunnableParallel(context=retriever, question=RunnablePassthrough())`\n",
    "    * `{\"context\": retriever, \"question\": RunnablePassthrough()}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010288fe-3891-4d9d-952b-c9c31c27e95c",
   "metadata": {},
   "source": [
    "## 使用 itemgetter 与 RunnableParallel\n",
    "* 当你用几个不同的输入变量调用 LLM 时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d721b7-6208-47c4-8a51-0104329a849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Accelera has trained more than 3,000 Enterprise Alumni. Arrr!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"AI Accelera has trained more than 5,000 Enterprise Alumni.\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many Enterprise Alumni has trained AI Accelera?\", \"language\": \"Pirate English\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50a4a2-8a4a-4f6a-ab4b-ac45d3cdb228",
   "metadata": {},
   "source": [
    "## 可运行分支：路由链\n",
    "* 可运行分支是一种特殊类型的可运行，它允许您根据输入定义一组条件和可运行项进行执行。\n",
    "* **可运行分支使用一对（条件，可运行项）及一个默认可运行项进行初始化**。它通过将每个条件与被调用时的输入进行传递，选择哪个分支。它选择第一个评估为 True 的条件，并使用输入运行与该条件对应的可运行项。\n",
    "* 对于高级使用，[自定义函数](https://python.langchain.com/v0.1/docs/expression_language/how_to/routing/) 可能比可运行分支更好的替代方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0108154-e304-4aa2-aa97-f64529a81ade",
   "metadata": {},
   "source": [
    "以下高级示例可以根据特定主题（如摇滚、政治、历史、体育或一般查询）对用户问题进行分类和响应。**它使用了一些我们将在下一节课中解释的新主题**。以下是每个部分的简化解释：\n",
    "\n",
    "1. **提示模板**：每个模板针对特定主题量身定制：\n",
    "   - **rock_template**：配置用于与摇滚相关的问题。\n",
    "   - **politics_template**：专门回答有关政治的问题。\n",
    "   - **history_template**：设计用于与历史相关的查询。\n",
    "   - **sports_template**：设置用于处理与体育相关的问题。\n",
    "   - **general_prompt**：用于不符合特定类别的一般查询的模板。\n",
    "\n",
    "   每个模板都包含一个占位符`{input}`，实际的用户问题将被插入其中。\n",
    "\n",
    "2. **可运行分支**：这是一个分支机制，根据问题的主题选择使用哪个模板。它评估条件（例如`x[\"topic\"] == \"rock\"`）来确定主题并使用适当的提示模板。\n",
    "\n",
    "3. **主题分类器**：一个Pydantic类，将用户问题的主题分类为预定义的类别之一（摇滚、政治、历史、体育或一般）。\n",
    "\n",
    "4. **分类链**：\n",
    "   - **链**：处理用户的输入以预测主题。\n",
    "   - **解析器**：从分类器的输出中提取预测的主题。\n",
    "\n",
    "5. **可运行直通**：该组件将用户的输入和分类的主题传递给可运行分支。\n",
    "\n",
    "6. **最终链**：\n",
    "   - 首先处理用户的输入以分类其主题。\n",
    "   - 然后根据分类的主题选择适当的提示。\n",
    "   - 选定的提示用于形成问题，然后发送给模型（如ChatOpenAI）。\n",
    "   - 模型的响应被解析为字符串并返回。\n",
    "\n",
    "7. **执行**：\n",
    "   - 链接通过一个示例问题调用，“拿破仑·博拿巴是谁？”\n",
    "   - 根据分类选择适当的模板，生成对聊天模型的查询，并处理响应。\n",
    "\n",
    "该系统有效地创建了一个动态响应生成器，根据询问的主题调整回答方式，利用不同主题的专业知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d269f55-2a46-4855-b5bc-095027386c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rock_template = \"\"\"You are a very smart rock and roll professor. \\\n",
    "You are great at answering questions about rock and roll in a concise\\\n",
    "and easy to understand manner.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "rock_prompt = PromptTemplate.from_template(rock_template)\n",
    "\n",
    "politics_template = \"\"\"You are a very good politics professor. \\\n",
    "You are great at answering politics questions..\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "politics_prompt = PromptTemplate.from_template(politics_template)\n",
    "\n",
    "history_template = \"\"\"You are a very good history teacher. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_prompt = PromptTemplate.from_template(history_template)\n",
    "\n",
    "sports_template = \"\"\" You are a sports teacher.\\\n",
    "You are great at answering sports questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "sports_prompt = PromptTemplate.from_template(sports_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083a779-e9fe-4dbf-9e0b-ead57ddfa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa09888-ee51-4f43-91c5-0f3136ce385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompt = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Answer the question as accurately as you can.\\n\\n{input}\"\n",
    ")\n",
    "prompt_branch = RunnableBranch(\n",
    "  (lambda x: x[\"topic\"] == \"rock\", rock_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"politics\", politics_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"history\", history_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"sports\", sports_prompt),\n",
    "  general_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b47e6-e3f4-4374-8f20-c0a884377d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.output_parsers.openai_functions import PydanticAttrOutputFunctionsParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "class TopicClassifier(BaseModel):\n",
    "    \"Classify the topic of the user question\"\n",
    "    \n",
    "    topic: Literal[\"rock\", \"politics\", \"history\", \"sports\"]\n",
    "    \"The topic of the user question. One of 'rock', 'politics', 'history', 'sports' or 'general'.\"\n",
    "\n",
    "classifier_function = convert_to_openai_function(TopicClassifier)\n",
    "\n",
    "llm = ChatOpenAI().bind(functions=[classifier_function], function_call={\"name\": \"TopicClassifier\"}) \n",
    "\n",
    "parser = PydanticAttrOutputFunctionsParser(pydantic_schema=TopicClassifier, attr_name=\"topic\")\n",
    "\n",
    "classifier_chain = llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f825ac1-df8b-4a6d-a24d-036b4c758e7b",
   "metadata": {},
   "source": [
    "`classifier_function` 类将用户问题的主题分类或归类为特定类别，例如“摇滚”、“政治”、“历史”或“体育”。以下是其简单的工作原理：\n",
    "\n",
    "1. **转换为函数**：它将`TopicClassifier` Pydantic 类（这是一个预定义的分类系统）转换为一个可以与 LangChain 容易使用的函数。这个转换过程包括对类的封装，以便能够在 OpenAI 模型中集成和执行。\n",
    "\n",
    "2. **主题检测**：当你输入一个问题时，该函数分析问题的内容，以确定它属于哪个类别或主题。它寻找与特定主题相匹配的关键词或模式。例如，如果问题是关于一个摇滚乐队，分类器会将主题识别为“摇滚”。\n",
    "\n",
    "3. **输出**：该函数以简单的标签输出所识别的主题，例如“摇滚”或“历史”。其他 LangChain 的部分然后使用该标签来决定如何处理问题，例如选择合适的模板来制定响应。\n",
    "\n",
    "从本质上讲，`classifier_function` 充当一个智能过滤器，帮助系统理解正在提出什么样的问题，以便能够更准确和相关地作出响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57438410-02c8-4808-abeb-1f941a7fafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(topic=itemgetter(\"input\") | classifier_chain) \n",
    "    | prompt_branch \n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf2559-318a-4d84-ae14-6582232b19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(\n",
    "    {\"input\": \"Who was Napoleon Bonaparte?\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
