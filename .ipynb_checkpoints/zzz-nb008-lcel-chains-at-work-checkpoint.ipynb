{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# LCEL chain at work in a typical RAG app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3f2ac-9ffb-493f-83d9-c4ba18f74559",
   "metadata": {},
   "source": [
    "## 让我们看看这个在典型的 RAG 示例中是如何工作的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3c150be-39db-4627-af38-9e6558d643ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865e3de-86b0-4852-bde7-53a949577fe7",
   "metadata": {},
   "source": [
    "* 请注意，我们从中心导入的提示有两个变量：“上下文”和“问题”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "614491a8-b569-472f-8fc5-17d99256fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef2ea3cf-17e2-4822-97fd-53b8f050e9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is the process of breaking down a task into smaller, more manageable subtasks in order to facilitate the completion of the overall task.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b035a7-4ff5-4a08-bc99-0f41d5b9d64e",
   "metadata": {},
   "source": [
    "#### 让我们详细看看 LCEL 链：\n",
    "* 正如您所看到的，链的第一部分是 RunnableParallel（请记住，RunnableParallel 可以有多种语法）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f45961b-42d9-4e39-8a3e-92c9de0d34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnableParallel({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89d1e16d-b38d-4983-94ad-97903a16939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique that breaks down complex tasks into smaller and simpler steps. It involves prompting the model to \"think step by step\" to make tasks more manageable. This process can be done using techniques like Chain of Thought or Tree of Thoughts.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbeb5b-36de-407f-9277-5f8cda94f90a",
   "metadata": {},
   "source": [
    "* 当我们调用这个链时，它是如何工作的：\n",
    "    * \"什么是任务分解？\" 被作为唯一输入传递。\n",
    "    * `context` 对输入执行检索。\n",
    "    * format_docs 对输入执行格式化函数。\n",
    "    * 输入被分配给 `question`。\n",
    "    * 使用先前的 `question` 和 `context` 变量定义提示。\n",
    "    * 模型使用先前的提示执行。\n",
    "    * 输出解析器对模型的响应执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d83a4a-8c77-47cf-a852-db2d3d7ec348",
   "metadata": {},
   "source": [
    "#### 注意：之前的格式化函数有什么作用？\n",
    "`format_docs`函数接受一个名为`docs`的对象列表。这个列表中的每个对象都应该有一个名为`page_content`的属性，该属性存储每个文档的文本内容。\n",
    "\n",
    "该函数的目的是从`docs`列表中的每个文档中提取`page_content`，然后将这些内容合并为一个单一的字符串。不同文档的内容通过两个换行符（`\\n\\n`）分隔，这意味着在最终字符串中，每个文档的内容之间会有一个空行。这种格式选择使得合并后的内容更易于阅读，因为它清晰地分隔了不同文档的内容。\n",
    "\n",
    "以下是该函数工作原理的分解：\n",
    "1. `for doc in docs`部分遍历`docs`列表中的每个对象。\n",
    "2. 在每次迭代中，`doc.page_content`访问当前文档的`page_content`属性，该属性包含其文本内容。\n",
    "3. `join`方法随后将这些文本片段连接成一个单一的字符串，在每个片段之间插入`\\n\\n`，以确保它们在最终结果中由空行分隔。\n",
    "\n",
    "该函数最终返回这个新格式化的单一字符串，其中包含所有文档内容，整齐地由空行分隔。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
