{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# 执行可运行项的替代方式\n",
    "* 调用、流和批处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ae74d-efe9-4d20-949f-0b57df6ee289",
   "metadata": {},
   "source": [
    "## 创建您的 .env 文件\n",
    "* 在 GitHub 仓库中，我们包含一个名为 .env.example 的文件\n",
    "* 将该文件重命名为 .env 文件，这里是您添加机密 API 密钥的地方。请记得包括：\n",
    "* OPENAI_API_KEY=你的_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=你的_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=你的项目名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "我们将我们的 LangSmith 项目称为 **004-invoke-stream-batch**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662650f0-fe77-42e8-8c1a-a61aff9b72f7",
   "metadata": {},
   "source": [
    "## 连接到位于该笔记本同一目录中的 .env 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b5d23-5d09-4c88-b32f-3299795cd91b",
   "metadata": {},
   "source": [
    "## LCEL链\n",
    "* **LCEL链是一系列可运行的组件。**\n",
    "* LangChain中的几乎任何组件（提示、模型、输出解析器、向量存储检索器、工具等）都可以用作可运行组件。\n",
    "* 可运行组件可以使用管道操作符`|`链接在一起。结果链的可运行组件本身也是可运行的。\n",
    "* LCEL链中元素的顺序（从左到右）是重要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a34484-0981-4edc-8ba2-7c8521d28c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246e32f8-4380-41d2-b33a-04ff4085569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Cristiano Ronaldo is that he is known for his incredible work ethic and dedication to his fitness. He reportedly has a biological age of 23, despite being in his mid-30s, demonstrating his commitment to maintaining peak physical condition.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1026d5-2e99-4fd4-af2a-ac2c6d2eeeac",
   "metadata": {},
   "source": [
    "* 链条的所有组件都是 Runnables。\n",
    "* **当我们写 chain.invoke() 时，我们以有序的方式使用所有链条组件的 invoke**：\n",
    "    * 首先，我们对提示模板应用 .invoke()，使用用户输入。\n",
    "    * 然后，用完成的提示，我们对模型应用 .invoke()。\n",
    "    * 最后，我们用模型的输出对输出解析器应用 .invoke()。\n",
    "* 重要提示：链条中的操作顺序非常重要。如果你尝试以不同顺序执行之前的链条，链条将会失败。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825056a-404d-4630-b5be-77130efaf0f8",
   "metadata": {},
   "source": [
    "## 让我们图示一下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31565f6-f04f-4afb-91c6-598814fd0877",
   "metadata": {},
   "source": [
    "![alt text](./lcel-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dafb72-bea0-422b-93ba-d8a0ab244019",
   "metadata": {},
   "source": [
    "## 现在让我们在不使用 LCEL 链的情况下复制这个过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6c802-2e5f-46e7-970b-5e336489c03e",
   "metadata": {},
   "source": [
    "#### 首先，我们将用户输入应用于提示模板，使用 .invoke()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5fbd44-6969-4d8f-ba83-ddd9e7d72193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a curious fact about Ronaldo')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ab4a4-999d-4640-9a62-886e4fdc5ce2",
   "metadata": {},
   "source": [
    "然后，使用完成的提示，我们对模型应用 .invoke()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede59f87-0be9-4fda-b6c4-dd521b62f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "output_after_first_step = [HumanMessage(content='tell me a curious fact about Ronaldo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7606951-561a-4679-8f59-8fdbd097734c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ronaldo is known for his incredible work ethic and dedication to training, often spending extra hours perfecting his skills on the field. He is said to have a training routine that includes up to 3,000 sit-ups per day.', response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 14, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9055f0ca-b5f7-4da7-a79b-99d7e47bb00a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 48, 'total_tokens': 62})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(output_after_first_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cc252-e57b-49e3-9887-7f4ccacbb4de",
   "metadata": {},
   "source": [
    "最后，我们将 .invoke() 应用到输出解析器，并使用模型的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a157968-1b54-4cf3-bc1d-d4ee4ff2b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "output_after_second_step = AIMessage(content='One curious fact about Cristiano Ronaldo is that he does not have any tattoos on his body. Despite the fact that many professional athletes have tattoos, Ronaldo has chosen to keep his body ink-free.', response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c9812511-043a-458a-bfb8-005bc0d057fb-0', usage_metadata={'input_tokens': 14, 'output_tokens': 38, 'total_tokens': 52})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074ea557-69b2-4eed-b9ba-4344d15c35d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Cristiano Ronaldo is that he does not have any tattoos on his body. Despite the fact that many professional athletes have tattoos, Ronaldo has chosen to keep his body ink-free.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(output_after_second_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123eadeb-a912-4c8b-b42e-af1a5f848977",
   "metadata": {},
   "source": [
    "## 执行可运行对象的方法\n",
    "* 请记住：\n",
    "    * LCEL 链是一系列可运行对象。\n",
    "    * LangChain 中的几乎任何组件（提示、模型、输出解析器等）都可以用作可运行对象。\n",
    "    * 可运行对象可以使用管道操作符 `|` 连接在一起。生成的可运行对象链本身也是可运行对象。\n",
    "    * LCEL 链中元素的顺序（从左到右）很重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf49277-35e5-4061-94f0-c79270203846",
   "metadata": {},
   "source": [
    "#### LCEL 链/可运行项用于：\n",
    "* chain.invoke(): 在输入上调用链。\n",
    "* chain.stream(): 在输入上调用链并流式返回响应的块。\n",
    "* chain.batch(): 在输入列表上调用链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3fe651b-dc5b-4067-a430-a4fa5da3faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me one sentence about {politician}.\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd006047-876e-4d5a-a116-e4124c4324af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston Churchill was a British statesman who served as Prime Minister during World War II.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 14, 'total_tokens': 32}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8ca53718-b566-4a64-be08-677702e4e887-0', usage_metadata={'input_tokens': 14, 'output_tokens': 18, 'total_tokens': 32})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"politician\": \"Churchill\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89db19ed-7425-4506-956f-4ebb3eae44f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.D. Roosevelt was the 32nd President of the United States and served during a time of great economic hardship and world conflict."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"politician\": \"F.D. Roosevelt\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea804f6-d7f1-41aa-a6ef-ee668b8d0705",
   "metadata": {},
   "source": [
    "#### for 循环的简单解释\n",
    "这个 `for` 循环用于逐块显示接收到的响应。以下是它的简单工作原理：\n",
    "\n",
    "1. **分块获取响应**：循环一次接收系统的一部分响应。在这个例子中，系统正在提供有关政治家“F.D. 罗斯福”的信息。\n",
    "\n",
    "2. **立即打印响应**：每当接收到新的响应部分时，立即将其打印出来。该设置确保各部分之间没有换行，因此看起来像是一个连续的响应。\n",
    "\n",
    "3. **无需等待**：通过使用这个循环，您不必等到整个响应准备好后才能开始查看其部分。这使得感觉更快，更像是一场对话。\n",
    "\n",
    "通过这种方式，循环有助于以更流畅和更互动的方式显示系统生成的响应。\n",
    "\n",
    "#### for 循环的技术解释\n",
    "这个 `for` 循环用于处理来自语言模型响应的流输出。以下是其功能和上下文的详细分解：\n",
    "\n",
    "1. **迭代流输出**：`for` 循环遍历 `chain.stream(...)` 返回的生成器。`chain` 对象的 `stream` 方法（这是一个提示模板和语言模型的组合）旨在逐步生成响应。这在模型的响应较长或需要实时显示时尤其有用。\n",
    "\n",
    "2. **数据获取**：在这个循环中，`s` 代表从模型流回的每一块内容，因为响应正在生成。在这种情况下，模型被设置为提供有关政治家“F.D. 罗斯福”的信息。\n",
    "\n",
    "3. **输出处理**：在循环内部，对于每一块流式内容都会调用 `print(s.content, end=\"\", flush=True)`。`print` 函数的定制包括：\n",
    "   - `end=\"\"`：该参数确保每块内容在打印时不会在后面添加换行，从而使响应在一行上连续显示。\n",
    "   - `flush=True`：该参数强制输出缓冲区在每个打印语句后立即刷新，确保每块内容在接收到后立即显示给用户，而不会有任何延迟。\n",
    "\n",
    "通过使用这个循环，代码能够在模型的响应可用时显示每个段落，使用户界面更加动态和响应迅速，特别是在需要及时反馈的实时应用中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b680921b-e75f-4d77-b655-22dc9a91e9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Lenin was a Russian revolutionary and politician who led the Bolshevik party to power during the October Revolution of 1917.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 14, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0d5ae3bf-268e-4c7b-bae0-53991c88bdc9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 24, 'total_tokens': 38}),\n",
       " AIMessage(content='Stalin was a ruthless dictator responsible for millions of deaths in the Soviet Union.', response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 14, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b5e99220-7665-49a4-a124-653027e78b8f-0', usage_metadata={'input_tokens': 14, 'output_tokens': 16, 'total_tokens': 30})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"politician\": \"Lenin\"}, {\"politician\": \"Stalin\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0a455-5f6b-4b32-8cef-4d6ccce13526",
   "metadata": {},
   "source": [
    "#### LCEL 链/可运行对象也可以异步使用：\n",
    "* chain.ainvoke(): 在输入上调用链。\n",
    "* chain.astream(): 在输入上调用链并流回响应的片段。\n",
    "* chain.abatch(): 在输入列表上调用链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feaa8ab-caa4-48a5-9a12-c14881889bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
